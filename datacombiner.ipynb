{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bf026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyarrow import csv\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "###### Loading and formatting traffic data #########################################################\n",
    "\n",
    "# Read the csv files into pandas DataFrames\n",
    "years = [\"2005\", \"2006\", \"2007\", \"2008\", \"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\"]\n",
    "weather = \"weatherData.csv\"\n",
    "holidays = \"Holidays.csv\"\n",
    "\n",
    "# Read the traffic data\n",
    "traffic_data = pd.DataFrame()\n",
    "for year in years:\n",
    "    traffic_file = f\"data/traffic-{year}.csv\"\n",
    "    traffic_df = pd.read_csv(traffic_file)\n",
    "    traffic_data = pd.concat([traffic_data, traffic_df], ignore_index=True)\n",
    "\n",
    "# convert dates to datetime\n",
    "traffic_data['Dato'] = pd.to_datetime(traffic_data['Dato'], format='%Y-%m-%d')\n",
    "\n",
    "# new dataframe with only Vej-ID and latlon\n",
    "latlon_df = traffic_data[[\"Vej-Id\", \"latlon\"]].drop_duplicates()\n",
    "# convert to a dictionary mapping Vej-Id to latlon\n",
    "latlon_dict = dict(zip(latlon_df[\"Vej-Id\"], latlon_df[\"latlon\"]))\n",
    "\n",
    "times = [\"kl.00-01\", \"kl.01-02\", \"kl.02-03\", \"kl.03-04\", \"kl.04-05\", \"kl.05-06\",\n",
    "         \"kl.06-07\", \"kl.07-08\", \"kl.08-09\", \"kl.09-10\", \"kl.10-11\", \"kl.11-12\",\n",
    "         \"kl.12-13\", \"kl.13-14\", \"kl.14-15\", \"kl.15-16\", \"kl.16-17\", \"kl.17-18\",\n",
    "         \"kl.18-19\", \"kl.19-20\", \"kl.20-21\", \"kl.21-22\", \"kl.22-23\", \"kl.23-24\"]\n",
    "times2 = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\",\n",
    "          \"6\", \"7\", \"8\", \"9\", \"10\", \"11\",\n",
    "         \"12\", \"13\", \"14\", \"15\", \"16\", \"17\",\n",
    "         \"18\", \"19\", \"20\", \"21\", \"22\", \"23\"]\n",
    "tdict = dict(zip(times, times2))\n",
    "\n",
    "# replace column names in traffic_data\n",
    "for k, v in tdict.items():\n",
    "    traffic_data.rename(columns={k: v}, inplace=True)\n",
    "\n",
    "# First, melt so that each row represents a station-hour combo\n",
    "traffic_long = traffic_data.melt(\n",
    "    id_vars=['Vej-Id','Vejnavn','Dato','lat','lon','latlon'],\n",
    "    value_vars=times2,\n",
    "    var_name='hour',\n",
    "    value_name='traffic_count'\n",
    ")\n",
    "\n",
    "# Ensure 'Dato' is datetime type\n",
    "traffic_long['Dato'] = pd.to_datetime(traffic_long['Dato'])\n",
    "\n",
    "# Convert hour string to integer, then to timedelta\n",
    "traffic_long['hour'] = traffic_long['hour'].astype(int)\n",
    "traffic_long['datetime'] = traffic_long['Dato'] + pd.to_timedelta(traffic_long['hour'], unit='h')\n",
    "\n",
    "traffic_wide = traffic_long.pivot(index='datetime', columns='Vej-Id', values='traffic_count')\n",
    "traffic_wide = traffic_wide.astype('Int64')  # capital 'I'\n",
    "\n",
    "# Optional: sort by datetime\n",
    "traffic_wide = traffic_wide.sort_index()\n",
    "\n",
    "# fill NaN values with -1\n",
    "traffic_wide = traffic_wide.fillna(-1)\n",
    "\n",
    "# data usage of df\n",
    "#print(traffic_wide.info(memory_usage='deep'))\n",
    "\n",
    "\n",
    "\n",
    "####### Loading and adding weather data ###########################################################\n",
    "\n",
    "# load weather data\n",
    "weather_data = pd.read_csv(\"data/\"+weather, sep=',',skiprows=3)\n",
    "weather_data['time'] = pd.to_datetime(weather_data['time'])\n",
    "\n",
    "# add wather data to traffic_wide, keep datetime as index\n",
    "traffic_wide = traffic_wide.join(weather_data.set_index('time'), on='datetime', how='left')\n",
    "\n",
    "\n",
    "\n",
    "###### Loading and adding holiday data ############################################################\n",
    "\n",
    "# load holidays data\n",
    "holidays_data = pd.read_csv(\"data/\"+holidays, sep=',')\n",
    "\n",
    "holidays_data['Date'] = pd.to_datetime(holidays_data['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# get date out of index and into column\n",
    "traffic_wide[\"Date\"] = traffic_wide.index\n",
    "\n",
    "traffic_wide[\"DayOfWeek\"] = traffic_wide[\"Date\"].dt.day_name()\n",
    "traffic_wide[\"isHoliday\"] = traffic_wide[\"Date\"].dt.date.isin(holidays_data[\"Date\"].dt.date.values)\n",
    "traffic_wide[\"isWeekend\"] = traffic_wide[\"DayOfWeek\"].isin([\"Saturday\", \"Sunday\"])\n",
    "traffic_wide[\"isWeekday\"] = ~traffic_wide[\"isWeekend\"]\n",
    "\n",
    "traffic_wide[\"holidayName\"] = traffic_wide[\"Date\"].dt.date.apply(\n",
    "    lambda x: holidays_data.loc[holidays_data[\"Date\"].dt.date == x, \"HolidayName\"].values[0] if x in holidays_data[\"Date\"].dt.date.values else None\n",
    ")\n",
    "traffic_wide[\"holidayType\"] = traffic_wide[\"Date\"].dt.date.apply(\n",
    "    lambda x: holidays_data.loc[holidays_data[\"Date\"].dt.date == x, \"HolidayType\"].values[0] if x in holidays_data[\"Date\"].dt.date.values else None\n",
    ")\n",
    "\n",
    "# drop the Date column\n",
    "traffic_wide.drop(columns=[\"Date\"], inplace=True)\n",
    "\n",
    "###### How to use the data #######################################################################\n",
    "\n",
    "# traffic_wide is the main dataframe, it contains the traffic data for all stations and all hours\n",
    "# it is indexed by datetime and has columns for each station (Vej-Id)\n",
    "# it also contains the weather data for each hour\n",
    "# and the holiday data, non holiday days are marked as \"isHoliday\" = False and will have missing values for \"holidayName\" and \"holidayType\"\n",
    "# the columns \"isWeekend\" and \"isWeekday\" are also added to indicate if the day is a weekend or a weekday\n",
    "\n",
    "# since stations have their own columns (for each direction and total), location is stored separately\n",
    "# to get location of a station, use the latlon_dict on column name (Vej-Id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26b48e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a parquet file\n",
    "traffic_wide.to_parquet(\"data/traffic_data.parquet\", engine='pyarrow', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ff0b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "traffic_wide.to_csv(\"data/traffic_data.csv\", index=True, sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
